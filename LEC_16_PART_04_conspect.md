# Метрики для классификации

## Задачи классификации

Все ранее рассмотренные метрики — accuracy, precision, recall, F1 — основаны на расчёте true positive, false positive и других показателей и применимы для решения задачи **жёсткой классификации**.

Для **мягкой классификации** можно перейти к жёсткой, сравнив предсказанную вероятность с некоторым порогом. В зависимости от значения порога будут получаться разные значения true positive, false positive и так далее в матрице ошибок.

## ROC-кривая

### Определение и построение

**ROC-кривая** (Receiver Operating Characteristic) пришла в статистику и машинное обучение из теории связи. Она строится в следующих осях:

- По оси X откладывается **false positive rate**, которая рассчитывается как отношение false positive к false positive plus true negative.
- По оси Y откладывается **true positive rate**, которая рассчитывается как отношение true positive к true positive plus false negative.

True positive rate полностью совпадает с метрикой recall. В литературе для true positive rate также можно встретить обозначение **сенситивности**.

Алгоритм построения ROC-кривой:

```mermaid
flowchart TD
    A[Перебор всех возможных значений порогов] --> B[Расчет TPR и FPR для каждого порога]
    B --> C[Упорядочивание предсказанных вероятностей]
    C --> D[Наблюдение y = -1: шаг порога вправо]
    D --> E[Наблюдение y = 1: шаг порога вверх]
    E --> F[Построение ROC-кривой из точки (0,0)]
```

![](images/LEC_16_PART_04/000209s_top_4.jpg)
![](images/LEC_16_PART_04/000229s_top_3.jpg)

### Свойства ROC-кривой

- Так как true positive rate и false positive rate — это некоторые доли, то все значения ROC-кривой будут лежать в единичном квадрате.
- Левая нижняя точка будет иметь координаты (0; 0).
- Правая верхняя точка будет иметь координаты (1; 1).
- Для идеального классификатора ROC-кривая будет проходить через точку (0; 1).
- Наибольшее значение true positive rate при наименьшем значении false positive rate.

В качестве единой метрики, которая оценивает качество предсказаний классификатора, можно использовать площадь под ROC-кривой. Для идеального классификатора площадь под ROC-кривой будет равна 1.

![](images/LEC_16_PART_04/000309s_top_5.jpg)

### Наихудший классификатор

Наихудшим классификатором с точки зрения машинного обучения является случайный классификатор, который каждое наблюдение предсказывает класс −1 или 1 с вероятностью 0,5. ROC-кривая для такого классификатора будет соответствовать диагонали единичного квадрата, и площадь под ней будет равна 0,5.

В статистике наихудшим классификатором считается тот, для которого ROC-кривая проходит через точку (1; 0), то есть площадь под которой равна 0.

![](images/LEC_16_PART_04/000349s_top_6.jpg)